{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will aggregate all the machine learning results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizations\n",
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Text processing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# ML algorithms\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load data</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = '../../data/yelp_academic_dataset_review.pickle'\n",
    "data = pd.read_pickle(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing all ('\\n') characters using list comprehensions\n",
    "data['text'] = [txt.replace('\\n', '') for txt in data['text']]\n",
    "\n",
    "# Taking only text and stars columns\n",
    "data = data.loc[:, ['text', 'stars']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Text representation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifiers and learning algorithms can not directly process the text documents in their original form, as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length. Therefore, during the preprocessing step, the texts are converted to a more manageable representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[\"text\"].tolist()\n",
    "y = data[\"stars\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def count_vectorize(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    \n",
    "    embedding = count_vectorizer.fit_transform(data)\n",
    "    \n",
    "    return embedding, count_vectorizer\n",
    "\n",
    "def tfidf_transform(data):\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    \n",
    "    text_freq = tfidf_transformer.fit_transform(data)\n",
    "    \n",
    "    return text_freq, tfidf_transformer\n",
    "\n",
    "X_train_counts, count_vectorizer = count_vectorize(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf, tfidf_transformer = tfidf_transform(X_train_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:center\">Evaluate Algorithms:Baseline </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We design our test harness.  We will use 5-fold cross-validation. We will evaluate algorithms using the accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 5\n",
    "seed = 42\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i style=\"color:MediumSlateBlue;\"> Let's create a baseline of performance on this problem and spot-check a number of different\n",
    "algorithms\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spot check algorithms\n",
    "## TODO : fill hyperparameters of the algorithms \n",
    "\n",
    "models = []\n",
    "\n",
    "models.append( ('NB', MultinomialNB()) )\n",
    "models.append( ('SGD', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-7, average=False, class_weight=None, epsilon=0.1, \\\n",
    "                                     eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',  max_iter=None, n_iter=5, n_jobs=1, power_t=0.5, \\\n",
    "                                     random_state=42, shuffle=True, tol=None, verbose=0, warm_start=False) )\n",
    "models.append( ('CART', DecisionTreeClassifier()) )\n",
    "models.append( ('GBM', GradientBoostingClassifier()) )\n",
    "models.append( ('RF', RandomForestClassifier(n_estimators=100)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will display the mean and standard deviation of accuracy for each algorithm as we calculate it and collect the results for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std() )\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 12))\n",
    "plt.title('Scaled Algorithms Comparison', fontsize=12)\n",
    "ax = fig.add_subplot(111)\n",
    "sns.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
